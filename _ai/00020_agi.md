---
title: "Post 20: Rumbo a la Inteligencia artificial general 🧠"
collection: ai
permalink: /ai/00020_agi
date: 2023-12-15
---

&nbsp;

Me parece loco que actualmente uno de los temas en ciencia con más foco sea el como "enseñarle" a las maquinas a pensar. ¿Como llegamos aquí?  

Personalmente, y quizás por ser biólogo, no creo que logremos crear una IA general en los siguientes 10 años como muchos apasionados de IA apuestan (y eso que también soy apasionado). Aunque el interés es tal que laboratorios como OpenAI contratan ingenieros con salarios de ~1.2 millones de MXN mensuales para investigar como enseñarle a pensar a las maquinas mediante metodos a los que han llamado "alineamiento", llegando incluso a usar otras IAs para alinear a las mismas IAs. 

![img](/images/ai/00020_agi.jpg)

Como aprendemos nosotros en relación con las IAs?. Por ejemplo, las IAs reciben 5 veces más información que un niño de 5 años y aun así las IAs no pueden alcanzar su capacidad de cognición (evidentemente).  Esto se debe a que nosotros tenemos conceptos previos, constantemente estamos recibiendo señales a traves de nuestros sentidos, y estas señales tienen asociados multiples significados; como el chocolate que al pensarlo recuerdas su sabor, olor, textura, contextos, etc (algo que en IA se le llama multimodalidad)
Y haciendo estimaciones de la cantidad de datos usados para entrenar IAs vs el vocablo que vamos aprendiendo a lo largo de nuestras vidas es que llegaron esta grafica (eje Y = cantidad de información, X = Años), donde se ve que IAs como esta llamada Chinchilla (que es una de las más optimizadas) consume mucha información y aun asi, ni a un niño se acerca.

![img](/images/ai/00020_agi2.jpg)

Refs:
* [Bridging the data gap between children and large language models](https://osf.io/preprints/psyarxiv/qzbgx)
* [BUn poco sobre el trabajo de OpenAI](https://openai.com/research/weak-to-strong-generalization)
* [BY un bonito seminario sobre la evolución de la conciencia](https://www.youtube.com/watch?v=9QWaZp_2I1k)


